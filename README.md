# üï∑Ô∏è App 2: Web Scraper Ass√≠ncrono e Profissional

Este projeto demonstra a constru√ß√£o de um **web scraper de alta performance** utilizando Python com as bibliotecas `asyncio` e `aiohttp`. Ele √© projetado para ser eficiente, robusto e respeitoso com os servidores de destino, incorporando funcionalidades essenciais para automa√ß√£o de dados em escala.

## ‚ú® Funcionalidades Principais

- **Processamento Ass√≠ncrono**: Utiliza `asyncio` e `aiohttp` para fazer m√∫ltiplas requisi√ß√µes HTTP em paralelo, aumentando drasticamente a velocidade de coleta de dados.
- **Rate Limiting Inteligente**: Inclui uma classe `RateLimiter` para controlar a frequ√™ncia das requisi√ß√µes, evitando sobrecarregar o servidor de destino e ser bloqueado.
- **Retry Autom√°tico com Exponential Backoff**: Tenta novamente requisi√ß√µes que falharam (ex: por timeout ou erro de rede) com um tempo de espera que aumenta exponencialmente, melhorando a resili√™ncia do scraper.
- **Logging Detalhado**: Fornece feedback em tempo real sobre o progresso do scraping, incluindo sucessos, avisos e erros.

## üõ†Ô∏è Tecnologias Utilizadas

| Tecnologia | Vers√£o | Prop√≥sito |
| :--- | :--- | :--- |
| **Python** | 3.11+ | Linguagem principal |
| **aiohttp** | 3.9.1 | Cliente/Servidor HTTP ass√≠ncrono |
| **BeautifulSoup4** | 4.12.2 | Biblioteca para parsing de HTML e XML |

## üìã Guia de Instala√ß√£o e Execu√ß√£o (Para Qualquer Pessoa)

Este guia foi feito para que qualquer pessoa, mesmo sem conhecimento t√©cnico, possa executar este projeto.

### Pr√©-requisitos

1.  **Git**: Ferramenta para baixar (clonar) o c√≥digo do GitHub.
    - [**Download do Git aqui**](https://git-scm.com/downloads)
2.  **Python**: A linguagem de programa√ß√£o usada no projeto (vers√£o 3.8 ou superior).
    - [**Download do Python aqui**](https://www.python.org/downloads/)
    - **Importante**: Durante a instala√ß√£o do Python no Windows, marque a caixa que diz **"Add Python to PATH"**.

### Passo 1: Baixar o Projeto (Clonar)

Abra o seu terminal (ou **Git Bash** no Windows) e use o comando abaixo para baixar o projeto:

```bash
git clone https://github.com/lucasandre16112000-png/02-web-scraper-async.git
```

### Passo 2: Entrar na Pasta do Projeto

```bash
cd 02-web-scraper-async
```

### Passo 3: Criar e Ativar um Ambiente Virtual

```bash
# No Windows
python -m venv venv
.\venv\Scripts\activate

# No macOS ou Linux
python3 -m venv venv
source venv/bin/activate
```

### Passo 4: Instalar as Bibliotecas do Projeto

```bash
pip install -r requirements.txt
```

### Passo 5: Executar o Scraper

```bash
python scraper.py
```

### Passo 6: Verificar os Resultados

- O terminal mostrar√° o progresso do scraping em tempo real.
- Ao final, um arquivo chamado `scraping_results.json` ser√° criado na mesma pasta, contendo todos os dados extra√≠dos.

## ü§î Solu√ß√£o de Problemas Comuns

- **`ModuleNotFoundError: No module named 'aiohttp'`**: Certifique-se de que o ambiente virtual (venv) est√° ativado (Passo 3) e que voc√™ instalou as depend√™ncias (Passo 4).
- **Erros de Conex√£o ou Timeout**: A internet pode estar inst√°vel ou o site alvo pode estar bloqueando requisi√ß√µes. O script j√° tenta lidar com isso, mas se o erro persistir, pode ser um problema de rede.

## üë®‚Äçüíª Autor

Lucas Andr√© S - [GitHub](https://github.com/lucasandre16112000-png)
